{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0acf1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 解决OpenMP库冲突问题\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce2cfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['tweet_id', 'entity', 'sentiment', 'tweet_content']\n",
    "train_data = pd.read_csv('data/twitter_training.csv', \n",
    "                        names=column_names,  \n",
    "                        encoding='utf-8')    \n",
    "\n",
    "validation_data = pd.read_csv('data/twitter_validation.csv', \n",
    "                             names=column_names,\n",
    "                             encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e358b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值统计:\n",
      "训练集:\n",
      "tweet_id           0\n",
      "entity             0\n",
      "sentiment          0\n",
      "tweet_content    686\n",
      "dtype: int64\n",
      "\n",
      "验证集:\n",
      "tweet_id         0\n",
      "entity           0\n",
      "sentiment        0\n",
      "tweet_content    0\n",
      "dtype: int64\n",
      "\n",
      "重复行数量:\n",
      "训练集: 2700\n",
      "验证集: 0\n",
      "\n",
      "情感标签分布:\n",
      "训练集:\n",
      "sentiment\n",
      "Negative      22542\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "验证集:\n",
      "sentiment\n",
      "Neutral       285\n",
      "Positive      277\n",
      "Negative      266\n",
      "Irrelevant    172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 检查缺失值\n",
    "print(\"缺失值统计:\")\n",
    "print(\"训练集:\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"\\n验证集:\")\n",
    "print(validation_data.isnull().sum())\n",
    "\n",
    "# 检查重复值\n",
    "print(f\"\\n重复行数量:\")\n",
    "print(f\"训练集: {train_data.duplicated().sum()}\")\n",
    "print(f\"验证集: {validation_data.duplicated().sum()}\")\n",
    "\n",
    "# 查看情感标签分布\n",
    "print(f\"\\n情感标签分布:\")\n",
    "print(\"训练集:\")\n",
    "print(train_data['sentiment'].value_counts())\n",
    "print(\"\\n验证集:\")\n",
    "print(validation_data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "212b56f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "原文 1: im getting on borderlands and i will murder you all ,\n",
      "清理后: im getting on borderlands and i will murder you all\n",
      "\n",
      "原文 2: Just like the windows partition of my Mac is like 6 years behind on its drivers So you have no idea how I didn’t notice\n",
      "清理后: just like the windows partition of my mac is like 6 years behind on its drivers so you have no idea how i didnt notice\n",
      "\n",
      "原文 3: Just realized between the windows partition of my Mac is like being 6 years behind on Nvidia drivers and cars I have no fucking idea how I ever didn ’ t notice\n",
      "清理后: just realized between the windows partition of my mac is like being 6 years behind on nvidia drivers and cars i have no fucking idea how i ever didn t notice\n",
      "总词汇数: 1342695\n",
      "唯一词汇数: 39744\n",
      "前10个高频词: [('the', 44445), ('i', 29191), ('to', 28830), ('and', 26591), ('a', 24127), ('of', 19444), ('is', 17824), ('for', 15611), ('in', 15399), ('this', 14666)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    文本清理函数\n",
    "    - 转换为小写\n",
    "    - 移除URL、用户名、特殊字符\n",
    "    - 移除多余空格\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # 转换为小写\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 移除URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 移除用户名 (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # 移除标点符号（保留空格）\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # 移除多余空格\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_data['cleaned_tweet'] = train_data['tweet_content'].apply(clean_text)\n",
    "validation_data['cleaned_tweet'] = validation_data['tweet_content'].apply(clean_text)\n",
    "\n",
    "# 查看清理前后的对比\n",
    "for i in range(3):\n",
    "    print(f\"\\n原文 {i+1}: {train_data['tweet_content'].iloc[-i]}\")\n",
    "    print(f\"清理后: {train_data['cleaned_tweet'].iloc[-i]}\")\n",
    "\n",
    "# 统计词汇\n",
    "all_words = []\n",
    "for tweet in train_data['cleaned_tweet']:\n",
    "    if tweet: \n",
    "        all_words.extend(tweet.split())\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "print(f\"总词汇数: {len(all_words)}\")\n",
    "print(f\"唯一词汇数: {len(word_freq)}\")\n",
    "print(f\"前10个高频词: {word_freq.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "768da539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 训练集: 73681 条数据\n",
      "  - 验证集: 1000 条数据\n"
     ]
    }
   ],
   "source": [
    "# 创建最终的处理后数据集\n",
    "processed_train = train_data[['tweet_id', 'entity', 'sentiment', 'cleaned_tweet']].copy()\n",
    "processed_validation = validation_data[['tweet_id', 'entity', 'sentiment', 'cleaned_tweet']].copy()\n",
    "\n",
    "# 移除空的推文\n",
    "processed_train = processed_train[processed_train['cleaned_tweet'].str.len() > 0]\n",
    "processed_validation = processed_validation[processed_validation['cleaned_tweet'].str.len() > 0]\n",
    "\n",
    "print(f\"  - 训练集: {len(processed_train)} 条数据\")\n",
    "print(f\"  - 验证集: {len(processed_validation)} 条数据\")\n",
    "\n",
    "# 保存处理后的数据\n",
    "# processed_train.to_csv('data/processed_train.csv', index=False)\n",
    "# processed_validation.to_csv('data/processed_validation.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
